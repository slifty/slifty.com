<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>MIT &#8211; Sorry for the Spam</title>
	<atom:link href="/category/work/mit/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>The Adventures of Dan Schultz</description>
	<lastBuildDate>Fri, 01 Apr 2016 21:55:56 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.7.2</generator>
	<item>
		<title>Information Ecolo-Tea</title>
		<link>/2012/06/information-ecolo-tea/</link>
					<comments>/2012/06/information-ecolo-tea/#comments</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Wed, 13 Jun 2012 15:16:13 +0000</pubDate>
				<category><![CDATA[Hilarity]]></category>
		<category><![CDATA[MIT]]></category>
		<category><![CDATA[bubble tea]]></category>
		<category><![CDATA[Friday Tea]]></category>
		<category><![CDATA[mischief]]></category>
		<category><![CDATA[MIT Media Lab]]></category>
		<category><![CDATA[occupy]]></category>
		<guid isPermaLink="false">/?p=994</guid>

					<description><![CDATA[You are about to hear an insider&#8217;s thrilling account of crashed markets, sinister minds, hunger, and inequality. For the tale to make sense you must understand a few things about the Media Lab. Thing #1: there are about 150 students and 200 &#8220;other&#8221; people spread across 25 research groups, 3 floors, and 2 buildings. In [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>You are about to hear an insider&#8217;s thrilling account of crashed markets, sinister minds, hunger, and inequality.  For the tale to make sense you must understand a few things about the Media Lab.</p>
<p><strong>Thing #1:</strong> there are about 150 students and 200 &#8220;other&#8221; people spread across 25 research groups, 3 floors, and 2 buildings.  In other words it is possible for any given individual to completely ignore at least half of the lab.  In an attempt to fight against anti-socialism, our community has a tradition called Friday Tea.  A different group hosts the entire lab for an hour long hangout every Friday afternoon.  This usually involves snacks such as cookies, chips, or whatever the group finds <a href="/2010/09/ode-to-food-cam/">on foodcam</a> that morning.  Sometimes there are activities, but mostly there is tea.</p>
<p><strong>Thing #2:</strong> my group, <a href="http://eco.media.mit.edu/">Information Ecology</a>, is notorious for being completely filled with <del>lovable</del> <a href="http://en.wikipedia.org/wiki/Troll_(Internet)">trolls</a>.  This reputation is deserved, which is reflected by the fact that when we host Friday Tea we use the opportunity to run social experiments on our peers.</p>
<h2>Experiment A: The Occupy BTea (Lab)</h2>
<p>It was November 4th and the world was <a href="http://en.wikipedia.org/wiki/Occupy_Wall_Street">protesting all around us</a>.  Our group&#8217;s crusty old PhD, <a href="http://web.media.mit.edu/~mhirsch/">Matt Hirsch</a>, had just sent out an announcement for the Media Lab community:</p>
<blockquote>
<p>The Information Ecology group is hosting tea this afternoon in the BT lab. Come occupy space with us at 4pm.</p>
<p>There will be 99% value brand plain vanilla duplex cookies, and 1% cake, which will be taken by the guest with the most expensive lobbyists.</p>
<p>The cake is not a lie.</p>
</blockquote>
<p><a href="/wp-content/uploads/2012/06/the_1_percent.jpg"><img loading="lazy" src="/wp-content/uploads/2012/06/the_1_percent-225x300.jpg" alt="The 1% Cake" title="the_1_percent" width="225" height="300" class="alignright size-medium wp-image-1030" srcset="/wp-content/uploads/2012/06/the_1_percent-225x300.jpg 225w, /wp-content/uploads/2012/06/the_1_percent.jpg 355w" sizes="(max-width: 225px) 100vw, 225px" /></a>Matt had taken the lead on this week&#8217;s ML Tea, and instead of doing something normal like buying a bunch of delicious cookies, chips, and popcorn, he picked up some off brand vanilla Oreos (the kind that sucks all the moisture out of your mouth) and a single, tiny, personal-sized cake.</p>
<p>Only a few people would be able to eat something they enjoyed; everyone else would have to subsist on the horrible cookies.  Since I unfortunately couldn&#8217;t attend, I asked Matt for some reflections.  Below are a few of his insightful comments about the experience:</p>
<p><strong>Q:</strong> What inspired the occupy tea?<br />
<strong>A:</strong> I think it was Ron Paul who said, &#8220;let them eat cake.&#8221; As good as that sounds, we weren&#8217;t sure they deserved cake. So we bought some really cheap cookies.</p>
<p><strong>Q:</strong> What do you think the result of the occupy tea says about our world?<br />
<strong>A:</strong>  It gives me hope that the cream really does rise to the top. Eventually, someone was bold enough to take the cake. She hoarded it all for herself and her friends, so the person with the best business acumen was rewarded, in tea as in life.</p>
<p><strong>Q:</strong> What were the best reactions?<br />
<strong>A:</strong>  Of course, the aforementioned conquering of the cake was the most rewarding to witness. But I also took a lot of pleasure from watching the shame &mdash; real visible shame &mdash; from the cookie eaters. It was their own pitiful inaction that sealed their cake-less fate, and you could tell that they only blamed themselves. Perhaps this will serve as some sort of object lesson for them.</p>
<p>And so the experience was a perfect success.  After some awkward confusion and pained cookie-eating someone took the cake and had a delicious feast among close friends in front of everyone.</p>
<div id="attachment_1029" style="width: 610px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2012/06/cookies_and_cake.jpg"><img aria-describedby="caption-attachment-1029" src="/wp-content/uploads/2012/06/cookies_and_cake.jpg" alt="Cookies and Cake" title="cookies_and_cake" width="600" class="size-full wp-image-1029" srcset="/wp-content/uploads/2012/06/cookies_and_cake.jpg 689w, /wp-content/uploads/2012/06/cookies_and_cake-300x225.jpg 300w" sizes="(max-width: 689px) 100vw, 689px" /></a><p id="caption-attachment-1029" class="wp-caption-text">The Occupy BTea (Lab) (Tea) took place on November 4th, 2011. A day that will live in infamy.</p></div>
<h2>Experiment B: The Bubble Tea Bubble</h2>
<p>The next semester rolled around and it was our turn to host tea again.  We needed a theme.  Our group loves bubble tea (sweet iced tea with tapioca pearls, also known as &#8220;Boba&#8221; in some strange places), and we wanted to share it with the lab.  Unfortunately that stuff is  expensive, so we couldn&#8217;t possibly buy enough for everyone.  Luckily we also love puns and mischief.  That stuff is cheap.</p>
<p>There was some email back and forth:</p>
<blockquote>
<p><strong>Me:</strong><br />
Hey everyone!</p>
<p>Turns out we&#8217;re hosting tea tomorrow, I knew that was coming up&#8230;  Anyone want to do anything special? Honestly we *should* be hosting bubble tea, but that&#8217;s expensive so I assume we won&#8217;t. We could buy some actual bubbles though (as in, people would spend all of tea blowing bubbles)</p>
<p><strong>Matt:</strong><br />
Can we host a bubble tea in the sense that everyone invests heavily in tea, driving the market to unrealistic levels, and then crashing, thus forcing all attendees to take a second mortgage on their mugs just to leave the lab space?</p>
<p><strong>Me:</strong><br />
Yes.  We need to brainstorm on this.</p>
</blockquote>
<p>Matt may not have been entirely serious in his suggestion, but it didn&#8217;t matter.  The high level theme had been decided.  After some deliberation we hatched a plan.  That plan became official soon after with the following announcement:</p>
<blockquote>
<p>Hello Media Lab and Friends,</p>
<p>Remember when we left the gold standard?  That was a great time to invest.  Same goes for the Internet in 1998 and 2012.</p>
<p>Anyway, we have some great real estate we&#8217;re trying to get rid of in the BT lab this afternoon at 4:00.  Come join everyone for Media Lab Tea in the Information Ecology space.</p>
<p>There will be <strong>FREE BUBBLE TEA</strong>, delicious snacks, and a wonderful activities!</p>
<p>Hugs, Kisses, and Bubbles,<br />
 &#8211; Information Ecology</p>
</blockquote>
<p><div id="attachment_1051" style="width: 238px" class="wp-caption alignright"><a href="/wp-content/uploads/2012/06/ticket.png"><img aria-describedby="caption-attachment-1051" loading="lazy" src="/wp-content/uploads/2012/06/ticket-228x300.png" alt="Bubble Tea Ticket" title="ticket" width="228" height="300" class="size-medium wp-image-1051" srcset="/wp-content/uploads/2012/06/ticket-228x300.png 228w, /wp-content/uploads/2012/06/ticket.png 300w" sizes="(max-width: 228px) 100vw, 228px" /></a><p id="caption-attachment-1051" class="wp-caption-text">This looks totally legitimate!</p></div>The scheme was simple.  Everyone would get one Information Ecology Bubble Tea Coupon and access to the standard tea fare (we provided real food this time) , but in order to get access to the &#8220;Bubble Tea Room&#8221; (which would open 30 minutes into the event) you would need three coupons.</p>
<p>Thus we set the groundwork for an economic bubble, creating a market based on goods whose implied value was not necessarily related to actual value</p>
<p>Our group&#8217;s advisor, Henry Holtzman, presented the tickets to students, staff, and faculty as they trickled in.  The rules were printed on the ticket and no additional instructions were given, so people had to figure things out for themselves.  &#8220;In tea as in life.&#8221;</p>
<p>Within minutes our lab was converted into a busy marketplace bubbling with capitalist energy.  Conversations were occurring left and right, people were making trades and striking deals.  Some, who either didn&#8217;t care about bubble tea or simply didn&#8217;t trust in their ability to get tickets, just gave them up for nothing.  Others made demands.  It didn&#8217;t take long for someone to shout out &#8220;I&#8217;ll pay $1 for a ticket!&#8221;  Matt and I just lurked on the sidelines and watched in awe.</p>
<p>Not everyone played by the traditional rules, of course.  There were threats of ticket counterfeit from students who scanned the tickets and warned us of their capacity to flood the market with fakes.  One person went so far as to physically steal the tickets from Henry.  All is fair on the tea market!</p>
<p>At 4:30 it was time to open the doors to the Information Ecology Bubble Tea Room.  We invited anyone with three tickets to the entrance, and a motley crew of about 20 people filtered from the crowd.  Some had partnered together, pooling their tickets and agreeing to share whatever tangible rewards might come (of course only one would be allowed in).  Others had fought and scraped their way to the top, achieving the status of three-ticket-holder through blood sweat and tears.</p>
<p>This was the finale.  The bubble was about to pop, and Matt and I needed to make sure we wouldn&#8217;t be nearby when it did.  We opened the door and rushed away as the investors began to enter (Matt was on crutches at the time, but he managed to move faster than me).</p>
<p>Inside the room, perched on a standing table, was a lone bubble tea.  This was done for effect, as there were 9 more in the refrigerator of assorted flavors and sizes.  The extra stash was found almost immediately, but it quickly began to sink in that there were still limited resources.  Only about half of the VIPs would see a payoff on their effort.</p>
<p>Nobody was shocked by the market crash &#8212; like I said, we have a reputation &#8212; but we hope that everyone learned a valuable lesson about bubble economies.  I think Henry felt a little bit bad about the whole thing.</p>
<p>Later, in the name of closure, we emailed the Media Lab community:</p>
<blockquote>
<p>Thank you all for experiencing an economic tea bubble with us. We sympathize with those who have been affected in this unforeseeable market adjustment. Due to extreme supply shortages, a threatened glut of counterfeit certificates, and ongoing physical security concerns, we cannot offer compensation for community members left with unfulfilled holdings. Additionally, the bubble tea room has been closed to further community access.</p>
<p>Take heart in the fact that Information Ecology is too big to fail, and in anticipation of a bail out will have its own private bubble tea outing in the near future.</p>
<p>God Bless.<br />
-Information Ecology</p>
</blockquote>
<p><a href="/wp-content/uploads/2012/06/teabubble.png"><img loading="lazy" src="/wp-content/uploads/2012/06/teabubble.png" alt="" title="teabubble" width="262" height="1024" class="aligncenter size-large wp-image-1056" /></a></p>
]]></content:encoded>
					
					<wfw:commentRss>/2012/06/information-ecolo-tea/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Truth Goggles Study Results</title>
		<link>/2012/06/truth-goggles-study-results/</link>
					<comments>/2012/06/truth-goggles-study-results/#comments</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Thu, 07 Jun 2012 14:21:35 +0000</pubDate>
				<category><![CDATA[MIT]]></category>
		<category><![CDATA[Truth Goggles]]></category>
		<category><![CDATA[academia]]></category>
		<category><![CDATA[credibility]]></category>
		<category><![CDATA[misinformation]]></category>
		<category><![CDATA[user study]]></category>
		<guid isPermaLink="false">/?p=821</guid>

					<description><![CDATA[Last month, I ran a user study to test the effectiveness of Truth Goggles (a credibility layer/B.S. detector for the Internet). The tool attempts to remind users when it&#8217;s important to think more carefully. If you&#8217;re curious, you can check out the demo page. Now that the study has officially concluded, the numbers have been [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Last month, I ran a user study to test the effectiveness of <a href="http://truthgoggl.es/">Truth Goggles</a> (a credibility layer/B.S. detector for the Internet). The tool attempts to remind users when it&#8217;s important to think more carefully. If you&#8217;re curious, you can check out <a href="http://truthgoggl.es/demo.html">the demo page</a>.<a href="http://truthgoggl.es/"><img loading="lazy" src="/wp-content/uploads/2012/06/logo.jpg" alt="Truth Goggles" title="Truth Goggles" width="270" height="140" class="alignright size-full wp-image-822" /></a></p>
<p>Now that the study has officially concluded, the numbers have been crunched, and the thesis has been submitted, I want to share what I learned from the resulting data and feedback.</p>
<p>I&#8217;ll warn you upfront: All conclusions drawn here should be taken with a grain of salt.  The participants were <em>not</em> a random sample of the Internet, and as such, the results don&#8217;t reflect the general population. I think they are quite exciting nevertheless!</p>
<h2>The  Questions</h2>
<p>There are many ways that a tool like Truth Goggles could be considered successful. A bare minimum is that users should prefer it to the non-augmented consumption experience (you know, the kind you have normally). Another measure of success might reflect the number of claims that users explored when the tool was enabled, or maybe the quality of that exploration.
</p>
<p>
These questions are interesting, but they all require different study designs. Here is what I considered when putting the study together.</p>
<ol>
<li><strong>Did people use Truth Goggles?</strong> It is difficult to accurately measure the use of a tool when working with a &#8220;captive&#8221; audience (i.e., study participants). Truth Goggles does not yet contain enough facts to be regularly useful in the real world, so the study had to simulate a reading experience and present articles with known fact-checked claims, so this question wasn&#8217;t explored too deeply.</li>
<li><strong>Did people enjoy using Truth Goggles?</strong> This study was run online, so the only way to get direct feedback was by asking users directly.  I also gave participants a chance to choose to enable or disable Truth Goggles for the final few articles after the tool has been completely exposed to them. Presumably, if they hated the interface they would have disabled it.</li>
<li><strong>Were users exposed to more fact checks?</strong> In order to compare a change we must have a baseline and the ability to measure exposure. This study wasn&#8217;t quite comprehensive enough to address this directly, although I did keep track of how often users chose to view &#8220;More&#8221; information about a fact check (which took them directly to <a href="http://www.politifact.com/">PolitiFact&#8217;s</a> site).</li>
<li><strong>Did users engage with the fact checks?</strong> To understand levels of engagement, the tool would need to keep track of what content was actually read and comprehended, as opposed to what content was simply rendered on a screen. Once again, tracking the use of the &#8220;More&#8221; button was a good indication of engagement.</li>
<li><strong>How well did Truth Goggles enable critical thinking?</strong> Although critical thinking doesn&#8217;t require a change of opinion, it seems reasonable to believe that a change of opinion does indicate thought. By measuring the drift in beliefs about fact-checked claims after using Truth Goggles, it was possible to  better understand the interface&#8217;s ability to facilitate updated beliefs.</li>
<li><strong>Did Truth Goggles affect levels of trust in consumption experiences?</strong> This question is deeply relevant, but given the format of this study I did not attempt to measure trust in a robust way. I did give users an opportunity to comment on how they felt Truth Goggles affected their trust.</li>
</ol>
<p>The final study design reflected aspects of each of these questions; however, &#8220;Did people enjoy using Truth Goggles,&#8221; &#8220;Did users engage with fact checks,&#8221; and &#8220;How well did Truth Goggles enable critical thinking&#8221; ended up getting the most focus.</p>
<h2>The Preparation</h2>
<p>Before the study began I selected, tagged, and pre-processed 10 political articles to create a pool of content that I knew would have fact-checked claims in them. For the most part, this involved going through PolitiFact, Googling the phrases, and hoping that some good articles would show up. Most of what I used was published in 2012 and came from a variety of sources with varying degrees of credibility.</p>
<p>I also added some tracking features to Truth Goggles in order to better understand what was clicked and explored. This meant I would know when users viewed a fact check or when they would interact with other parts of the interface. Finally, I had to create the actual study website, which added some randomization and guided participants through the process.</p>
<h2>The Participants</h2>
<p>The study was conducted online over the course of five days. Participants were recruited through email and Twitter. When I did the initial number crunching there were a total of 219 participants, 88 of whom completed the entire process. These numbers increased to 478 and 227, respectively, before the study officially concluded. This analysis reflects my thesis work, and only considers results from the original 88 participants who completed the entire study.</p>
<p>Unfortunately, the participant pool contained a disproportionate number of friends, individuals familiar with the concept of Truth Goggles, and professionals already aware of the challenges surrounding media literacy. The vast majority (about 90%) of those who actually completed the process were strong and moderate liberals. All of these biases were anticipated, but nevertheless they significantly limit the potential impact of the study.</p>
<h2>The Process</h2>
<p><a href="/wp-content/uploads/2012/06/science.png"><img loading="lazy" src="/wp-content/uploads/2012/06/science.png" alt="Stand back, I&#039;m going to try science!" title="science" width="300" height="300" class="alignright size-full wp-image-879" srcset="/wp-content/uploads/2012/06/science.png 300w, /wp-content/uploads/2012/06/science-150x150.png 150w, /wp-content/uploads/2012/06/science-100x100.png 100w" sizes="(max-width: 300px) 100vw, 300px" /></a>From start to finish, the study took each participant around 20 or 30 minutes. After being shown the initial instructions, people were asked to rate 12 claims on a truth scale from 1 to 5. They only had 10 seconds per claim to answer, so this was really trying to get at a person&#8217;s gut reaction based on the information sitting in his or her head.</p>
<p>After the survey was completed, the treatments began. Everyone was shown a series of 10 articles which contained the previously rated claims. The first two articles were always shown with Truth Goggles disabled. The next six were presented with different Truth Goggles interfaces to help call out fact-checked phrases. For the final two articles, participants were able to choose one of the four interfaces (including &#8220;None&#8221;).</p>
<p>Once the article reading ended, participants were asked to re-rate the claims from the beginning of the study. At this point, they had been exposed to explanations and context for most of them, so this time they were supposedly providing &#8220;informed&#8221; answers as opposed to gut feelings. After the second round of ratings, the study wrapped up with a short exit survey, where participants had a chance to yell at me in the comments and tell me what they thought about the experience.</p>
<h2>The Irony</h2>
<p>Before going any further, I want to be clear that Truth Goggles does not assume that fact-checking services are correct. To the contrary, the hope is that users will question fact checks just as much as they would question any source, and consider all evidence with scrutiny. This philosophy is problematic for evaluation, because it is difficult to measure belief accuracy without considering something to be &#8220;true.&#8221;</p>
<p>Lacking a better metric, the source verdicts (i.e., PolitiFact&#8217;s ratings) were used as grounding for accuracy for this analysis. This means that from an evaluation perspective, I considered interfaces to be more effective if users ended up with beliefs in line with PolitiFact&#8217;s verdicts. Since belief dissemination is not the goal of Truth Goggles, the system must eventually use more sources (e.g., <a href="http://www.factcheck.org/">Factcheck.org</a> and <a href="http://www.snopes.com/">Snopes</a>) to keep users on their toes.</p>
<h2>The Results</h2>
<p>In my thesis, I slice and dice the study data in more ways than I care to think about. But this isn&#8217;t my thesis, so I&#8217;m going to spare everyone a lot of pain and stick to the high-level observations.</p>
<ul>
<li><strong>Truth Goggles increased accuracy and decreased polarization.</strong> Participants changed their beliefs about the fact-checked claims after reading the articles, regardless of whether or not a credibility layer was rendered. But without Truth Goggles those updates resulted in more polarization and less accuracy. In particular, when Truth Goggles was disabled people tended to become overly trusting of claims that appeared in articles. With Truth Goggles active, however, beliefs became nuanced and more accurate.</li>
<li><strong>When using credibility layers, people became less incorrectly skeptical but they remained just as incorrectly trusting.</strong> Truth Goggles was able to help skeptics become more trusting when trust was appropriate, but was not as effective at convincing false believers that they should become more doubtful. This means that participants who were not already overly trusting of a claim would tend to update their beliefs in a way that resulted in more accuracy when using a credibility layer. If you incorrectly believed a claim, however, you weren&#8217;t likely to correct yourself.</li>
<li><strong>Normal reading caused people to become more incorrectly trusting but they remained just as incorrectly skeptical.</strong> Without a credibility layer, participants who were not already overly distrusting of a claim would tend to overly trust that claim after reading its related article. This means that if someone was highly skeptical of a claim before reading the article, they wouldn&#8217;t change their minds. But if they were more neutral or already trusting, then seeing the claim in an article would cause them to believe it more strongly.</li>
<li><strong>Almost everyone enabled Truth Goggles when given a choice.</strong> Only two out of the 88 participants who completed the study chose to view their final articles without using some variation of Truth Goggles. The vast majority of participants (70%) selected &#8220;highlight mode,&#8221; the least obtrusive of the three possible interfaces. These numbers unfortunately don&#8217;t mean much because it is entirely possible that participants simply wanted to play with the tool. They could be far worse, though.</li>
<li><strong>There were virtually no significant differences between the three interface types.</strong> It was no surprise that &#8220;Highlight Mode&#8221; was the most popular, since it did nothing but highlight text and didn&#8217;t bully people into clicking things. Less anticipated was the fact that &#8220;Safe Mode&#8221; and &#8220;Goggles Mode,&#8221; which force exploration, did not outperform Highlight Mode. I suspect that this was a study artifact &#8212; forced interaction was unnecessary during the study because the novelty of Truth Goggles meant people might be curious enough to click regardless of the interface &#8212; but it was interesting nonetheless.</li>
</ul>
<p>The short version of these results is that Truth Goggles helped combat misinformation, but there is still plenty of room for improvement. There also clearly needs to be a more comprehensive, longer-term user study.</p>
<p>For me, the big surprise was that that people were so prone to trusting content just because it appeared in an article or opinion piece. I was absolutely thrilled to see that effect get completely squelched through credibility layers. The results from the exit survey are also incredibly exciting, but that is a post for another day.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2012/06/truth-goggles-study-results/feed/</wfw:commentRss>
			<slash:comments>7</slash:comments>
		
		
			</item>
		<item>
		<title>Media Labs and Open News</title>
		<link>/2012/06/media-labs-and-open-news/</link>
					<comments>/2012/06/media-labs-and-open-news/#respond</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Tue, 05 Jun 2012 21:10:19 +0000</pubDate>
				<category><![CDATA[Life]]></category>
		<category><![CDATA[MIT]]></category>
		<category><![CDATA[OpenNews]]></category>
		<category><![CDATA[academia]]></category>
		<category><![CDATA[decisions]]></category>
		<category><![CDATA[transition]]></category>
		<guid isPermaLink="false">/?p=797</guid>

					<description><![CDATA[With my thesis complete I&#8217;m about to embark on the next phase in life, and in true Millennial fashion it will last about 10 months because job security is for chumps. I&#8217;m going to be a Knight-Mozilla Fellow (feel free to call me &#8220;Mr. Fellow&#8221;) working in The Boston Globe as part of the Open [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>With my thesis complete I&#8217;m about to embark on the next phase in life, and in true Millennial fashion it will last about 10 months because job security is for chumps.  I&#8217;m going to be a Knight-Mozilla Fellow (feel free to call me &#8220;Mr. Fellow&#8221;) working in <a href="http://bostonglobe.com/">The Boston Globe</a> as part of the <a href="http://opennews.org/">Open News</a> project led by the <a href="http://www.knightfoundation.org/">Knight Foundation</a> and the <a href="http://www.mozillafoundation.org/">Mozilla Foundation</a>.</p>
<p>My first full day was yesterday and I&#8217;m just about finished a post about my first impressions and lessons learned.  Before I hit publish on that, though, I want to give a nod to the option I decided <em>not</em> to pursue: a PhD at the MIT Media Lab.</p>
<h2>Choosing a Path</h2>
<p>I ultimately decided not to apply to the PhD program at the Media Lab for now.  This wasn&#8217;t easy (and doesn&#8217;t mean I won&#8217;t come back and apply later), but it came down to a few points:</p>
<p><img loading="lazy" src="/wp-content/uploads/2012/06/yunodoctorate-e1338930095522.jpg" alt="" title="yunodoctorate" width="280" height="280" class="alignleft size-medium wp-image-803" srcset="/wp-content/uploads/2012/06/yunodoctorate-e1338930095522.jpg 280w, /wp-content/uploads/2012/06/yunodoctorate-e1338930095522-150x150.jpg 150w, /wp-content/uploads/2012/06/yunodoctorate-e1338930095522-100x100.jpg 100w" sizes="(max-width: 280px) 100vw, 280px" /></p>
<p><strong>I&#8217;m not really a great academic.</strong>  Don&#8217;t get me wrong, the motto of &#8220;Demo or Die&#8221; generally trumps &#8220;Publish or Perish&#8221; at the Media Lab, but this doesn&#8217;t change the fact that a PhD is ultimately an academic endeavor.  When it comes to technology my natural inclination is to code and blog, not to design studies and write scientific papers.</p>
<p><strong>I got a huge amount out of my time at the lab.</strong> Yes, the awesome ability of the Media Lab to jump start lives is actually part of why I&#8217;m moving on.  In two years I feel empowered to create anything I want, I&#8217;ve redefined my understanding of the world, quadrupled my confidence, developed an amazing network of friends and connections, and  become part of a wonderful community.  I&#8217;m sure that four more years at the lab would continue improvement on all of those fronts, but I doubt that it would be nearly as saturated.</p>
<p><strong>Four years is much longer than 10 months.</strong> Call me an opportunist but I&#8217;m married, and who knows where Lyla and I will want to be over the next four years.  Actually it turns out we do know (Lyla got into RISD and starts her graduate program in September), but that isn&#8217;t the point.  Locking myself into something for four years seems dangerous at a time when there are so many problems to solve and ideas to pursue.  What would have happened if Luke just chilled out with Yoda for four years?</p>
<p>All of that being said, if I ever commit to a PhD it will be at the Media Lab.  I already miss the place!  Luckily I&#8217;ll stay an official part of it for at least another year as a &#8220;zero cost visiting researcher.&#8221;  This means I don&#8217;t get paid, but I get to keep access to resources and have a good explanation as to why I&#8217;m still skulking around the hallways at night.</p>
<p>This leaves me here, living the Tolkien dream and beginning a brand new fellowship.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2012/06/media-labs-and-open-news/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Achievement Unlocked: Thesis</title>
		<link>/2012/05/achievement-unlocked-thesis/</link>
					<comments>/2012/05/achievement-unlocked-thesis/#comments</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Mon, 21 May 2012 06:00:21 +0000</pubDate>
				<category><![CDATA[MIT]]></category>
		<category><![CDATA[Truth Goggles]]></category>
		<category><![CDATA[credibility]]></category>
		<category><![CDATA[insights]]></category>
		<category><![CDATA[thesis]]></category>
		<guid isPermaLink="false">/?p=756</guid>

					<description><![CDATA[Remind me to never do that again. On Friday I officially handed in my thesis, titled &#8220;Truth Goggles: Automatic Incorporation of Context and Primary Source for a Critical Media Experience.&#8221; For those who don&#8217;t know already, it was about an automated bullshit detector for the Internet / an interface to help people think carefully called [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Remind me to never do that again.</p>
<p>On Friday I officially handed in my thesis, titled &#8220;Truth Goggles: Automatic Incorporation of Context and Primary Source for a Critical Media Experience.&#8221; For those who don&#8217;t know already, it was about an automated bullshit detector for the Internet / an interface to help people think carefully called Truth Goggles. The final version weighed in at a nice round 145 pages.</p>
<p>I&#8217;ll let the dust settle before putting this monstrosity online. I also want to write some more condensed posts about the interesting parts because I know nobody is ever going to read the damn thing. Those will come later. For now I give you a few bullet points.<br />
<span id="more-756"></span></p>
<h2>The Gist</h2>
<p>Here&#8217;s the basic story of the document:</p>
<ul>
<li>I learned about the millions and millions of reasons why my idea could never work.</li>
<li>Not having a strong sense of self preservation I kept on going anyway and tried to create &#8220;Truth Goggles!&#8221;</li>
<li>I worked really hard to design and implement <a href="http://truthgoggl.es/demo.html">an interface</a> that people could value even if they didn&#8217;t trust the sources behind the tool.</li>
<li>I ran a user study and learned that the interfaces worked pretty well when it came to protecting people from misinformation, and that almost everyone who took the study really wants to be able to trust information again.</li>
</ul>
<h2>The Gems</h2>
<p>I&#8217;ll give a quick preview of some lessons learned. Each of these points deserves a post of its own but since this isn&#8217;t my thesis I&#8217;m going to just put out my own observations and thoughts. The posts later will probably be more &#8220;scientific&#8221; and &#8220;explanatory&#8221; (i.e. &#8220;boring&#8221; and &#8220;less quotable&#8221;).</p>
<ul>
<li><strong>When people consume information they are struggling hard to maintain their identity.</strong> That&#8217;s all there is to it. There is plenty of evidence that people consume information with ideological motivations. Those motivations often cause them to accept or reject information based on how well it aligns with what they already believe. I have a theory that if you could just remind someone that there&#8217;s nothing to fear — that you aren&#8217;t trying to change who they are — you will suddenly be able to actually communicate with them.</li>
<li><strong>Trying to tell people what to think is a losing battle.</strong> When the first round of press for Truth Goggles came out back in 2011 I paid attention to every single comment on every single report about the idea I could find. Lots of people liked it, but a lot of people were instantly dismissive due to concerns about bias. I heard their point, agreed with it, and realized what journalists saw ages ago: there is no way to create a universally respected system that also tells people what to think. I changed course and settled for a system that would remind people <em>when</em> to think instead. I think that is a better mission anyway.</li>
<li><strong>Credibility breeds respect, and respect breeds open minds.</strong> Several participants in the Truth Goggles user study commented that having a credibility layer made them more willing to consider perspectives and messages that they might have normally ignored completely. Think about that for a second. It makes sense, right? It is much easier to respect what a person is saying if you can trust them. Usually &#8220;respect&#8221; and &#8220;trust&#8221; are like &#8220;chicken&#8221; and &#8220;egg&#8221;, but if you&#8217;re using something like Truth Goggles it is possible to develop trust and let the respect follow if it ends up being deserved.</li>
</ul>
<p>This entire experience has given me a lot of hope about information online and the people who consume it. I&#8217;ve said before that <a href="/2011/12/trust-me-credibility-is-the-future-of-journalism/">credibility was the future of journalism</a> and I&#8217;m half tempted to expand that statement to say that credibility could save the world. I&#8217;ll probably need to run a few more tests though.</p>
<p>As for the next steps for Truth Goggles, that is to be determined! I&#8217;m going to at least keep exploring some of the processes and technologies behind phrase detection, but once I graduate and start my fellowship at the Boston Globe in June I&#8217;ll need an explicit way to keep it alive. Stay tuned.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2012/05/achievement-unlocked-thesis/feed/</wfw:commentRss>
			<slash:comments>6</slash:comments>
		
		
			</item>
		<item>
		<title>Trust Me: Credibility is the Future of Journalism</title>
		<link>/2011/12/trust-me-credibility-is-the-future-of-journalism/</link>
					<comments>/2011/12/trust-me-credibility-is-the-future-of-journalism/#comments</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Sun, 11 Dec 2011 22:32:54 +0000</pubDate>
				<category><![CDATA[MIT]]></category>
		<category><![CDATA[Truth Goggles]]></category>
		<category><![CDATA[credibility]]></category>
		<category><![CDATA[journalism]]></category>
		<guid isPermaLink="false">/?p=692</guid>

					<description><![CDATA[My colleague Matt Stempeck said it best: &#8220;Dan, I know that your life has been a tornado wrapped in a hurricane wrapped up in a whole box of tsunamis this week, but you really need to start wearing pants to work.&#8221; It turns out only part of that quote is accurate, but you&#8217;ll never know [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>My colleague <a href="http://www.pbs.org/idealab/matt_stempeck/">Matt Stempeck</a> said it best: &#8220;Dan, I know that your life has been a tornado wrapped in a hurricane wrapped up in a whole box of tsunamis this week, but you really need to start wearing pants to work.&#8221;</p>
<p>It turns out only part of that quote is accurate, but you&#8217;ll never know which one for sure!  This is why, before I can graduate from MIT, I have to create an automated bullshit detector.  The basic premise is that we, as readers, are inherently lazy.  It isn&#8217;t just that we&#8217;ll believe almost anything &#8212; remember that time in 1938 when we believed aliens were invading the planet just because someone on the radio said so?  Yeah. <a href="http://en.wikipedia.org/wiki/The_War_of_the_Worlds_(radio_drama)">That happened</a>.  The real problem is that we&#8217;ll often believe what we want to believe (or disbelieve what we don&#8217;t want to believe).</p>
<p>It&#8217;s hard to blame us.  Just look at the amount of information flying around every which way.  Who has time to think carefully about everything?  Not me, that&#8217;s who&#8217;nt.  This is why I&#8217;m working on a tool called <a href="/2011/08/introducing-truth-goggles/">Truth Goggles</a> that will help hone our <a href="http://www.urbandictionary.com/define.php?term=Critical%20Ability">critical abilities</a>; one that will help us identify pieces of information that are worth inspecting a little bit more closely before deciding how it fits into our world views.</p>
<h2>Thesis Goggles</h2>
<p>When I wrote &#8220;before I can graduate from MIT&#8221; earlier in this post I wasn&#8217;t lying; I have decided to pursue Truth Goggles for my thesis. I&#8217;m definitely <a href="http://confront.intel-research.net/Dispute_Finder.html">not the first</a> person <a href="http://hypothes.is/">to explore</a> this problem space but there is a lot of room to contribute.  New technology has opened up new possibilities, needs have become clearer, and there is a wide variety of possible solutions and unanswered questions just sitting around waiting to be explored.</p>
<p>In November I presented the idea to the Media Lab community using the following slides:</p>
<div style="width:425px" id="__ss_10158861"> <strong style="display:block;margin:12px 0 4px"><a href="http://www.slideshare.net/slifty/crit-day-presentation-truth-goggles" title="Crit Day Presentation (Truth Goggles)" target="_blank">Crit Day Presentation (Truth Goggles)</a></strong> <iframe loading="lazy" src="http://www.slideshare.net/slideshow/embed_code/10158861" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe> </p>
<div style="padding:5px 0 12px"> View more <a href="http://www.slideshare.net/" target="_blank">presentations</a> from <a href="http://www.slideshare.net/slifty" target="_blank">Daniel Schultz</a> </div>
</p></div>
<p>The feedback I got was mixed, but what can you expect from a day called &#8220;Crit Day&#8221; which is short for &#8220;Critically Injure Pride, Hopes, and Dreams of Graduating Day.&#8221; Here were the main questions asked:</p>
<p><strong>This doesn&#8217;t seem like it will scale considering Politifact only has a few thousand fact checked claims.  Why aren&#8217;t you using the crowd to fact check?</strong></p>
<p>My time at MIT will be spent focusing on the interface and user interaction rather than the generation and aggregation of source information.  There are enough difficult questions surrounding the interaction layer.  I don&#8217;t think it is worth complicating things further by trying to create a crowd-based journalism platform (which is essentially what crowd sourced fact checking amounts to).</p>
<p><strong>Isn&#8217;t this just a mashup of technologies and data sets?  How is what you are doing novel?</strong></p>
<p>It&#8217;s true that I&#8217;m not inventing new algorithms.  I&#8217;m applying existing algorithms in novel ways.  Credibility layers aren&#8217;t robust right now, and they come with their own sets of interesting questions in terms of user experience and system design.  My contribution will be to frame those questions, answer some of them, create a prototype, and test that prototype.  This won&#8217;t be as trivial as just throwing more information on a screen and calling it a day, the interface has to be designed with care.</p>
<p><strong>Do you expect to incorporate primary source data?</strong></p>
<p>My initial prototype probably won&#8217;t pull from sources other than <a href="http://www.politifact.com/">Politifact</a> and other fact checking services, but I will definitely be thinking about ways to use other sources of data. Primary source content will eventually help with information scalability since raw footage and raw data could help computers find potentially dubious claims (and help readers make determinations about those claims).</p>
<h2>Bullshit, This is Clearly Science Fiction</h2>
<p>There are a lot of hard questions lurking behind corners here.  In fact, most of them aren&#8217;t even trying to hide; they&#8217;re just sitting obnoxiously in the middle of the room.  Some are technical, some are philosophical, but all of them need to be addressed intelligently for something like Truth Goggles to actually have a chance of working.  I&#8217;ll rattle off a few of them.</p>
<ul>
<li>Who determines the truth?  Journalists?  Experts?  Crowds?  Individuals?  Algorithms?</li>
<li>Sometimes there is a right answer and sometimes there is room for debate.  Can you tell which is which?  How do you reflect the difference?</li>
<li>How does the tool account for bias in sources?</li>
<li>How does the tool account for bias in users?</li>
<li>Will the system actually know enough to be regularly useful?</li>
<li>This could easily just make consumers more lazy, how do you prevent that?</li>
<li>What happens when the tool is wrong?</li>
<li>How will this change the way people produce content?</li>
<li>Where do Journalists fit into the picture?</li>
</ul>
<p>As I&#8217;ve pondered these questions I&#8217;ve come to the following absolute conclusion: Credibility layers need to empower <a href="http://www.urbandictionary.com/define.php?term=Critical%20Ability">critical ability</a>.  I&#8217;ve also decided that it&#8217;s OK for the system to make mistakes but it is never allowed to lie.  This means the interface should be less focused on telling the reader what to think and much more focused on reminding (and helping) the reader to think at times when thinking is most important.</p>
<p>I&#8217;ve also come up with a list of weaker claims to throw out there for discussion:</p>
<ul>
<li>Credibility layers don&#8217;t have to speak to everyone, but they need to empower the open minded.</li>
<li>Journalists are our best bet for deep analysis and identifying truth that requires lots of time and effort (e.g. investigation and concept synthesis).</li>
<li>Algorithms are our best bet for identifying contextual evidence (e.g. data, trends, and sources of sound bytes).</li>
<li>Mobs can&#8217;t be trusted to decide what is true and false, but they are the key to figuring out what is worth thinking about.</li>
</ul>
<p>Over the coming months I&#8217;ll be cranking out interfaces, prototypes, and eventually some good old fashioned boring academic papers about this idea.  In the mean time if you&#8217;re interested in Truth Goggles I&#8217;ll be trying to post updates as regularly as possible on <a href="http://www.slifty.com/">my blog</a>, on twitter (<a href="http://www.twitter.com/slifty">@slifty</a>), and eventually on the newly registered <a href="http://truthgoggl.es/">truthgoggl.es</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2011/12/trust-me-credibility-is-the-future-of-journalism/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>Remixing Mainstream Media</title>
		<link>/2011/11/remixing-mainstream-media/</link>
					<comments>/2011/11/remixing-mainstream-media/#respond</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Wed, 02 Nov 2011 06:49:26 +0000</pubDate>
				<category><![CDATA[MIT]]></category>
		<category><![CDATA[NewsJack]]></category>
		<category><![CDATA[memes]]></category>
		<category><![CDATA[remixes]]></category>
		<guid isPermaLink="false">/?p=675</guid>

					<description><![CDATA[As we all know the most important part of any successful project is completely changing your idea at the last minute. In that spirit I am about to present a progress update on a project that has nothing to do with the revamped IRC interface I outlined last time (note that the IRC project isn’t [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>As we all know the most important part of any successful project is completely changing your idea at the last minute.  In that spirit I am about to present a progress update on a project that has nothing to do with the <a href="http://civic.mit.edu/blog/schultzd/rethinking-the-irc-experience">revamped IRC interface</a> I outlined last time (note that the IRC project isn’t dead, but I’ll be working on it over IAP instead).</p>
<p>Here’s my new plan: I am going to make it possible for anyone to control the content of front page of the New York Times.  Want your kid’s little league game in the local news?  That’s cool, but you know what’s cooler?  Having your kid’s fame story smack dab front and center next to the article about Osama Bin Laden’s assassination.  Suddenly little Billy is the talk of more than just the town, he’s the talk of the entire world!</p>
<p>Interested?  Well hang onto your hats because I’m about to teleport to a completely different topic.</p>
<h2>How to Manipulate the Masses: A Simple Guidebook</h2>
<p>People say the Internet is liberating and I suppose that can be true; however, as a wise man named Ethan Zuckerman once said, it isn’t enough to have a voice.  What you really need is an audience.   For the average digital Joe or Janet that audience is probably something between zero and maybe a few thousand people.  If you didn’t realize it from that last sentence I’m saying your audience is smaller than a colony of ants.  Hell, what you have isn’t even captive, so good luck getting more than a few minutes of collective attention across your entire network in a given day!</p>
<p>How does it feel to know that your personal media power quotient, even with access to the latest and greatest forms of communication in all of human history, is pretty close to zilch?  Feels bad, right?  Kind of makes you not want to bother trying to do anything at all?</p>
<p>Well suck it up because you aren’t alone.  In fact, “you aren’t alone” is exactly why so many grassroots messages have spread in a land of noise and tweets: they go viral.  If everyone gets two minutes of daily attention from a network then the only way for to spread a message is to hijack your network’s airtime too.  More importantly, you have to do so in a way that equips all of those people to hijack THEIR networks too.</p>
<p>You can get your network to share by either:</p>
<ul>
<li>Pushing something that they will agree with (curse you filter bubble.)</li>
<li>Pushing something that is amazing</li>
<li>Pushing something that is hilarious</li>
<li>Cats</li>
</ul>
<p>Keep in mind that comments on your content will do almost nothing for spreading messages beyond one network step, which is why “pushing something that will piss them off” isn’t on the list.  “Cats” is a placeholder for the type of content that, as of now, is the only way to get to consistently get a network’s network to share.</p>
<p>Anyone who was holding a hat can let go now because I’m going to talk about my project again.  For those who didn’t care before but whose interested has piqued now it’s your turn to hat hold.  For everyone else, why are you still reading this? </p>
<h2>Taming the Meme</h2>
<p>I met Ben Huh, the owner of ICanHasCheebzburger.com, last week at a 2012 election coverage summit.  If that sentence meant nothing to you, I’m basically saying I met a viral god.  The nearby newsfolk peppered him with questions about how to use memes to spread their own messages.  His response was simple: you probably can’t.  It is so difficult to harness a meme because they come from a digital version of whisper down the lane (or “Telephone” if you’re from that other part of the country). People add twists, there is no central control, and this is almost tautologically part of why the thing becomes popular to begin with.</p>
<p>Memes spread because they easy to shape, which is how people can use them in ways that are exciting enough to share.  Boom, viral content achieved</p>
<p>My proposed system is one that will hijack an <a href="http://www.hackasaurus.org/">existing tool</a> to make it easy to twist and turn the front page of the New York Times, to share those twists with a network, and to have members of that network add (and share) further twists of their own.  I also want this system to track the changes; I want to build a conversation around the evolution of a given strain of modifications.  I would even like to help incorporate some real content into the picture since I have the real estate; maybe some actual news can slip or fade its way in sometimes.</p>
<p>The end result is more than a simple stage for content sharing.  Through very minor forms of control (in the form of history and tracking and known context) it becomes possible to infuse the adapting content with useful information layers.  Boom, meaningful viral content achieved.</p>
<p>Oh, and for the record, remix-and-share services do exist (consider <a href="http://www.technologyreview.com/computing/38928/page1/">Startup Spirit</a> vs <a href="http://slifty.bo.lt/ht3mo">Citrus Flavoring</a>) but they are systems designed to provide a technology.  I&#8217;m proposing a system designed to empower viral conversations.</p>
<p><em>This has been <a href="http://civic.mit.edu/blog/schultzd/remixing-mainstream-media">cross posted</a> on the civic blog.</em></p>
]]></content:encoded>
					
					<wfw:commentRss>/2011/11/remixing-mainstream-media/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Learning Lab Final Project: ATTN-SPAN</title>
		<link>/2011/08/learning-lab-final-project-attn-span/</link>
					<comments>/2011/08/learning-lab-final-project-attn-span/#comments</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Tue, 09 Aug 2011 11:36:50 +0000</pubDate>
				<category><![CDATA[ATTN-SPAN]]></category>
		<category><![CDATA[Learning Lab]]></category>
		<category><![CDATA[MIT]]></category>
		<category><![CDATA[Truth Goggles]]></category>
		<category><![CDATA[ATTN-Span]]></category>
		<category><![CDATA[bookmarklet]]></category>
		<category><![CDATA[C-SPAN]]></category>
		<category><![CDATA[government]]></category>
		<guid isPermaLink="false">/?p=434</guid>

					<description><![CDATA[Part 1: Introduction ATTN-SPAN Intro. Part 2: Prototype and Development Plan The Good News: I created a proof of concept prototype of the ATTN-SPAN platform powered by the Metavid project. The Bad News: Metavid is having a lot of stability issues right now, so you probably won’t be able to use my prototype. I made [&#8230;]]]></description>
										<content:encoded><![CDATA[<h2>Part 1: Introduction</h2>
<p><iframe loading="lazy" src="http://player.vimeo.com/video/27480773?title=0&amp;byline=0&amp;portrait=0" width="400" height="300" frameborder="0"></iframe></p>
<p><a href="http://vimeo.com/27480773">ATTN-SPAN Intro</a>.</p>
<h2>Part 2: Prototype and Development Plan</h2>
<p><strong>The Good News:</strong> I created a proof of concept <a href="http://bit.ly/qt8q4e" target="_blank">prototype of the ATTN-SPAN platform</a> powered by the <a href="http://metavid.org/" target="_blank">Metavid</a> project.</p>
<p><strong>The Bad News:</strong> Metavid is having a lot of stability issues right now, so you probably won’t be able to use my prototype.  <a href="http://vimeo.com/27473310" target="_blank">I made a screen cast just in case.</a></p>
<p>Relying on a 3rd party for the most important aspect of an application is a major risk; one that I must mitigate. This brings me to my first batch of design work: the content scraper.</p>
<h3>Scraping, Slicing, and Scrubbing C-SPAN</h3>
<p>How do you get from a TV channel to a rich video archive and how do you get there automatically?  The goal is to convert C-SPAN into a series of overlapping video segments that are identified in terms of state, politician, topic, party, action, and legislative item.  Some of this is straightforward and some of it might be impossible, but here’s an overview of the planned nuts and bolts:</p>
<ol>
<li>DirecTV offers TV content in a format that is easy to record digitally and <a href="http://www.videolan.org/" target="_blank">VLC</a> is a free tool that can do that recording.  Combine the two and we can download C-SPAN streams into individual files that are primed and ready for analysis.</li>
<li>Once a video file is in our clutches we can use VLC once again to separate out the video from the Closed Captioning transcript.</li>
<li>Now we have a transcript and a raw video file.  Next we register all of this information (in a database) so that we can look it all up later, and then convert the video file in to streaming-friendly formats and store it alongside the original recording.</li>
<li>C-SPAN consistently shows a graphic on the bottom of the screen that says who is talking, their state, their party, and what is being debated.  By using a technique called <a href="http://en.wikipedia.org/wiki/Optical_character_recognition" target="_blank">Optical Character Recognition (OCR)</a> we can pull this text out of the video image.  Once pulled, we can add that to our database so that we can access all of this information for any moment in the video.</li>
<li>At this point we have most of the information we need, but there is still room for fine tuning.  We can use audio levels and the closed captioning transcripts to try to identify moments of inactivity, normal dialogue, and heated dialogue.</li>
</ol>
<p>These steps are enough to split up and categorize C-SPAN footage into an organized video database, but there are still more ways to flag special moments in the footage.  For example, we may want to identify changes in speaker emotion in order to give our algorithms the ability to craft more engaging episodes. This is possible through the work of <a href="http://affect.media.mit.edu/" target="_blank">Affective Computing</a> group at the MIT Media Lab, a group which has developed several tools that perform emotional analysis using facial recognition.</p>
<p>We may also want to identify specific legislative action (e.g. “calling a vote”).  This could be accomplished by looking for key words in the transcript (e.g. &#8220;call a vote&#8221;) and possibly through common patterns in the audio signal (maybe there are identifiable sounds, such as a gavel hitting the table).  Both of these concepts require additional research.</p>
<h3>Creating a Profile and Constructing an Episode</h3>
<p>If video events are the building blocks then viewer interests are the glue.  The creation of a personalized episode requires two things: A user account, and a context.  The user account provides general information like where you live, what issues you have identified as important, and (if you are willing to connect with Twitter or Facebook) what issues your circles have been discussing lately.</p>
<p>The context comes from time and cyberspace.  Every night, after congress closes their gates, your profile is used to create a short, rich video experience designed to contain as much relevant content from that day as possible.  At this point you might get an email begging you to watch, or maybe you log in on your own because you are addicted to badges and points and you want as much ATTN-SPAN karma as you can get.</p>
<p>There is another way to access this content though, and that is through the web sites you visit anyway.  Imagine if you could read an article about the National Debt on the New York Times (or in a chain email) and actually see quotes from your own senators in the report.  What if you could supplement the national report with a video widget that lets you browse what your house members had to say when they controlled the floor during the debt debates.</p>
<p>From a technical perspective this isn&#8217;t that far fetched.  <a href="/2011/08/introducing-truth-goggles/" target="_blank">Truth Goggles</a>, one of my other projects, is a <a href="http://en.wikipedia.org/wiki/Bookmarklet" target="_blank">bookmarklet</a> that will analyze the web page you are viewing, fact check it, and rewrite the content to highlight truths and lies.  This impossible feat is fairly similar to what I&#8217;m proposing here.</p>
<h3>Adding Rich Information</h3>
<p>Once an episode is pieced together we can look up the information surrounding the video to know who is talking and what they are talking about.  What else can be added and how do we get it? Existing APIs offer some good options:</p>
<ul>
<li><strong>Contact Information</strong> &#8211; Thanks to the <a href="http://services.sunlightlabs.com/docs/Sunlight_Congress_API/" target="_blank">Sunlight Labs Congress API</a> it is possible to get the contact information for any member of congress on the fly.  Thanks to VOIP services it is possible to create web-based hooks to call those people with the click of a button.</li>
<li><strong>Campaign Contributions</strong> &#8211; The New York Times offers a <a href="http://developer.nytimes.com/docs/campaign_finance_api/" target="_blank">Campaign Finance API</a> which can help you understand where the person on screen gets his or her money.</li>
<li><strong>Voting Records</strong> &#8211; The New York Times also offers a <a href="http://developer.nytimes.com/docs/read/congress_api" target="_blank">Congress API</a> that will make it possible to know vote outcomes from related bills as well as information about the active speaker&#8217;s voting records.</li>
<li><strong>Truth and Lie Identification</strong> &#8211; My <a href="/2011/08/introducing-truth-goggles/" target="_blank">Truth Goggles</a> project can be easily adapted to work with snippets from video transcripts.  This will allow ATTN-SPAN to take advantage of fact checking services like PolitiFact and NewsTrust.</li>
</ul>
<p>This is a good start, but I would also like to show links to related news coverage and create socially driven events based on community sentiment (for instance to track moments that caused people to get upset or happy).  This won&#8217;t come for free, but it should be accessible given the right interface design.</p>
<h2>Part 3: A Note to the Newsies</h2>
<p>So that&#8217;s the idea and the plan.  What&#8217;s the value?</p>
<p>It seems plausible that ATTN-SPAN, a system that analyzes primary source footage and pulls out any content that is related to a particular beat could be useful as a reporters tool, but what about your subscribers?  ATTN-SPAN can augment an individual article so that it hits everybody close to home.  Suddenly one article becomes as effective as two dozen.  Moving past text, for larger organizations with a significant amount video footage ATTN-SPAN can be tweaked to use your programming instead of (or in addition to) C-SPAN.</p>
<p>At this point I have to warn you that this is not the first nor will it be the last project to work with C-SPAN.  A 2003 demo out of the Media Lab used C-SPAN as one of several sources of information in a platform aimed to provide citizens with <a href="http://web.mit.edu/newsoffice/2003/gia.html" target="_blank">Total Government Awareness</a>.  <a href="http://metavid.org/" target="_blank">Metavid</a>, the platform I used in my initial prototype, already makes C-SPAN more accessible by enabling searches and filters.  The list surely goes on.</p>
<p>So why is this a more powerful project?  Well, the real goal of ATTN-SPAN isn&#8217;t to get more people watching C-SPAN.  In fact I tricked you: this project isn&#8217;t about government awareness at all.  It&#8217;s actually part of an effort to make indisputable fact (&#8220;blunt reality&#8221; and &#8220;primary source footage&#8221;) a more prominent part of the media experience without requiring additional effort from the audience.  Newsrooms do an amazing job of reporting events and providing insight, but for deeper stories there simply isn&#8217;t enough time or money to cover everybody&#8217;s niche without going beyond the average person&#8217;s attention span.</p>
<p>Thus ends my pitch.</p>
<p><em>The code for both prototypes mentioned in this post can be found on github: <a href="https://github.com/slifty/ATTN-SPAN">ATTN-SPAN</a> and <a href="https://github.com/slifty/Critical">Truth Goggles</a>.  Please forgive any dirty hacks.  I would be thrilled if anybody wants to offer suggestions or even collaborate.  On that note, please get in touch on Twitter <a href="http://twitter.com/slifty" target="_blank">@slifty</a>.</em></p>
]]></content:encoded>
					
					<wfw:commentRss>/2011/08/learning-lab-final-project-attn-span/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
			</item>
		<item>
		<title>Introducing Truth Goggles</title>
		<link>/2011/08/introducing-truth-goggles/</link>
					<comments>/2011/08/introducing-truth-goggles/#comments</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Mon, 01 Aug 2011 20:21:56 +0000</pubDate>
				<category><![CDATA[MIT]]></category>
		<category><![CDATA[Truth Goggles]]></category>
		<category><![CDATA[demo]]></category>
		<guid isPermaLink="false">/?p=345</guid>

					<description><![CDATA[I&#8217;m working on a magical button.  This button, when pressed, will tell you (an average person who just wants to know what is happening in this crazy world) what is true and what is false on the web site you are viewing. I have a fair amount of the platform finished already and you can [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>I&#8217;m working on a magical button.  This button, when pressed, will tell you (an average person who just wants to know what is happening in this crazy world) what is true and what is false on the web site you are viewing.  I have a fair amount of the platform finished already and you can <a href="http://critical.istheinternetabigtruck.com/" target="_blank">check it out here</a>. <b>Be warned: Right now it only knows one fact.  I&#8217;m workin&#8217; on it!</b>  Reading a news article?  Click the button and see how much you can trust it. Reading an email from Uncle Jim saying that the sky is falling?  Not so fast Uncle Jim!  Oh wait&#8230; no nevermind it turns out he&#8217;s right this time.</p>
<p>Anyway, I wanted to explain a bit about how this all works, which will in turn help me organize my thoughts on what the next steps are going to be.  First, some important terminology:</p>
<p>A <strong>Claim</strong> is a general statement that is intended to be factual but, in reality, could use a bit of fact-checking by a third party (i.e. it is not trivially true).</p>
<p><p>A <strong>Snippet</strong> is an instance of a claim &#8212; it is the place where a claim is referenced, for example, a newspaper article or a tweet.</p>
<p>A <strong>Verdict</strong> is the truth of a claim &#8212; this is determined by fact checking organizations who  have spent a lot of time looking at the big picture and coming to a logical conclusion.</p>
<p>For instance, if the statement &#8220;The U.S. government calculates inflation without adding in the price of food and energy&#8221; is a claim, then this would be an example of a snippet (With the context being the entire snippet, and the content being &#8220;the government removed food and energy prices from its measure of inflation to hide rising prices&#8221;):</p>
<blockquote><p>While advising his Fox News viewers to talk about inflation at their Thanksgiving dinners, Glenn Beck falsely claimed that the government removed food and energy prices from its measure of inflation to hide rising prices, that a survey showed economists are “worried” about inflation, and that Social Security recipients are not receiving a cost-of-living adjustment because the government &#8220;changed the calculation.&#8221;</p></blockquote>
<p>Want to see it in action?  <del datetime="2011-11-29T02:43:15+00:00">Try clicking this link: <a href="javascript:var%20criticalDomain='http://critical.istheinternetabigtruck.com/';var%20s=document.createElement('script');s.type='text/javascript';document.body.appendChild(s);s.src=criticalDomain+'/critical.min.js';void(0);">Apply Truth Goggles</a></del> <b>(Be warned, it doesn&#8217;t work <del datetime="2011-11-29T02:43:15+00:00">in Internet Explorer</del> at all right now)</b></p>
<p>Each claim will have many snippets, but each snippet will have one claim.  A snippet has context (for instance the entire tweet) and content (the portion of the tweet that is a paraphrase of the claim).</p>
<p>So where does a Claim come from, and how does it get associated with snippets?</p>
<h2>The Birth of a Claim</h2>
<p>Claims are pulled from fact checking services such as <a href="http://newstrust.net/truthsquad">NewsTrust</a> and <a href="http://www.politifact.org/">Politifact</a>.  This gets me:</p>
<ul>
<li>The claim&#8217;s text</li>
<li>The claim&#8217;s verdict (true, mostly true, mostly false, false, under evaluation)</li>
<li>The URL for more information about the claim&#8217;s verdict (If you want to know WHY something is true or false)</li>
<li>Additional information links (sites that provide information about the claim)</li>
<li>Additional context (descriptions, words, tags, etc. which will allow us to understand what the claim concerns)</li>
</ul>
<p>At this point we have the claim and a bunch of information surrounding the claim.  So how does a claim become linked to a snippet?  And how do snippets get identified on a web page?  These are the difficult questions for this project and they have a few possible solutions.</p>
<h2>Creating snippets</h2>
<p>First off, a snippet is automatically created for each claim &#8212; the automatically generated snippet is simply one that has the claim as both the content and the context. (i.e. the claim &#8220;Cows turn purple once every three years at midnight&#8221; would have a snippet of the exact same text, so that if anyone directly wrote that snippet it would be properly identified).</p>
<p>That&#8217;s great, but there might be snippets that reference the claim without using any of the same words.  For instance there might be a paragraph on color changing cows with the sentence &#8220;bovines turn violet about three times a decade&#8221; or the even more linguistically convoluted &#8220;Unlike dogs, cows are known to change their color.&#8221;  Both of those represent new snippets that are related to the cow claim.  How do we link them up?</p>
<p>There are three basic flavors of answer: automatically, by hand, or a mix of the two (semiautomatically).  Going by hand is not ideal because that puts a lot of reliance on the end user to be willing to spend a lot of time digging through claims and snippets and connecting the dots.  Going automatically would be wonderful, but it kind of requires a computer to be able to understand language &#8212; as you might expect, this is not an easy problem.  This is where the hybrid becomes attractive.  For a given proposed snippet the computer can do its best to identify any claims that it think really might be related.  Then it can ask the user to help out if they are willing.  Then, if the user says so, the snippet can be associated with the claim and down the line it will know for sure.</p>
<h2>Associating snippets to content</h2>
<p>Once we have a database of claims and snippets we want to be able to associate them with the web content that a user sends in for analysis.  (i.e. when you click your truth goggles button and the server runs through the content looking for snippets so that it can highlight claims.  I have two choices here: I can either do the simple and reliable method of looking for perfect matches (i.e. a snippet has to perfectly match the text) or I can try to be a little more clever.  In this case I am going to the less clever route, because the whole point of the snippet *creation* process is to cover the cases where there is text that is really close to a snippet.</p>
<p>The next steps are:</p>
<ul>
<li>Designing and implementing the snippet creation process</li>
<li>Designing an interface to present the verdicts and claim information in more detail</li>
<li>Writing scripts to update the claims with the latest results from fact checking databases</li>
</ul>
<p>The long term ways that this project could be expanded are:</p>
<ul>
<li>Incorporating social media to aid in claim and verdict mining</li>
<li>Adding in the ability to view news through the lens of RELATIVE truths rather than just the attempted absolute truth.  For instance, what would a superliberal democrat believe?  What would a tea party member believe?  What do people from Ohio think?</li>
</ul>
<p>And with that, it&#8217;s time to continue hacking away!</p>
]]></content:encoded>
					
					<wfw:commentRss>/2011/08/introducing-truth-goggles/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>A Pumpkin Festival</title>
		<link>/2010/12/a-pumpkin-festival/</link>
					<comments>/2010/12/a-pumpkin-festival/#respond</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Fri, 31 Dec 2010 18:54:37 +0000</pubDate>
				<category><![CDATA[Hilarity]]></category>
		<category><![CDATA[MIT]]></category>
		<category><![CDATA[laser cutter]]></category>
		<category><![CDATA[making]]></category>
		<category><![CDATA[pumpkin]]></category>
		<category><![CDATA[StarCraft]]></category>
		<guid isPermaLink="false">/?p=239</guid>

					<description><![CDATA[I have a love for a spectacular game called StarCraft 2.  It’s a sequel to one of the best video games ever created, made in 1998, StarCraft. To give you an idea of how great StarCraft is &#8211; it is a national sport in South Korea. Television stations are dedicated to broadcasting games between professional [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>I have a love for a spectacular game called <a href="http://starcraft2.com/" target="_blank">StarCraft 2</a>.  It’s a sequel to one of the best video games ever created, made in 1998, StarCraft.</p>
<p>To give you an idea of how great StarCraft is &#8211; it is a national sport in South Korea. Television stations are dedicated to broadcasting games between professional players on a 24/7 cycle.  Think chess but the board is digital terrain, the pieces are infantry, and instead of taking turns everyone moves their pieces at once.</p>
<p>You might ask “why are you talking about StarCraft in a post about pumpkins?“ Well there is a good answer.  The answer is that Blizzard, the company that created StarCraft, has an annual pumpkin carving competition.  This year I decided to give it a shot (spoiler alert: I didn’t win).</p>
<h2>The beginning of the journey</h2>
<p>I’m not crafty and I don’t have any skill when it comes to slicing gords, but I have advantage.  You see, I have access to thousands of dollars of equipment!  In particular I have access to a laser cutter.  A laser cutter is exactly what it sounds like – a machine that uses LASERS to cut things.  The lasers are attached to the heads of sharks.</p>
<p>I wanted to try this novel technique but assumed that the folks who run the shop wouldn’t be thrilled with the idea of putting pumpkins in their expensive equipment so I let the idea die.  A week later my friend (and fellow Info Eco member) Matt Hirsch found a picture of a pumpkin carved into the death star online and declared his own interest in cutting pumpkins with the laser cutter.  This tipped the scales.</p>
<p>I rushed out and bought a test pumpkin.</p>
<h2>Understanding Laser Cutters</h2>
<p>Laser cutters cut on two axes.  This means they can make cuts in two dimensions.  Think of an ink jet printer only instead of putting ink on spot they burn away the material there.  The laser is attached to a head, which can move forward, backward, left and right.  You put the material underneath it, focus the laser, and let it work magic.</p>
<p>Laser cutters are great at cutting shapes out of flat things like cardboard, or sheets of wood, or acrylic. They aren’t so great at cutting shapes in pumpkins.  `Luckily our shop has a device that converts round things into flat things – it turns the laser cutter into a laser lathe.  Instead of having the laser move forward and backward, the laser only moves left and right, and this device spins whatever it is you want to cut.</p>
<p>The cuts themselves are designed digitally as a drawing.  You just “print” the picture you want, and the laser will burn away the material to match the image you printed.  Of course there’s a bit more to it than that.  Vector (i.e. line drawing) images are used to make lines.  Raster (i.e. solid shapes) images are used to burn away large areas of material.  Vector is far faster than raster, but raster is needed for certain kinds of effects.</p>
<h2>Science!</h2>
<p>After gutting my test pumpkin it was time to give the cutting a shot.  I didn’t know what settings would work – I wanted to be able to cut through the pumpkin in certain spots, but I also needed to be able to make shallow cuts, since the most fancy pumpkins tend to have different depth cuts in them to create different shades of orange.</p>
<p>Cutting through was a breeze, but required very slow settings.  The big issue was that because the pumpkin isn’t a cylinder it curves down on the sides.  This means that the surface is further away from the laser and so the laser loses focus and intensity as it moves further away from the center (i.e. lines that are closer to the sides are wider and shallower).</p>
<p>It was also clear that the bottleneck to this whole process would be pumpkin size.  The lathe attachment can’t hold objects that were wider than about 7 inches, so I would only be able to cut shapes on tiny pumpkins.  Blast!</p>
<h2>Design #1: Tassadar</h2>
<p>Since StarCraft has a fan base, there is a lot of artwork out there.  I just had to pick one I thought would look good on a pumpkin, and convert the image to a format that a laser cutter would understand.</p>
<p>I wanted to try making a pumpkin with four layers.  The first layer wouldn’t be cut at all (darkest), the second and third would be different depths of raster art, and the fourth would be cut all the way through (lightest).  I used Adobe Illustrator to “trace” the image I had selected.  This process converts a full-fledged image into a much simpler one; in my case the new image had only four colors.</p>
<div id="attachment_912" style="width: 620px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/12/Tassadar_SC2_Cncpt1.jpg"><img aria-describedby="caption-attachment-912" loading="lazy" src="/wp-content/uploads/2010/12/Tassadar_SC2_Cncpt1.jpg" alt="Tassadar" title="Tassadar_SC2_Cncpt1" width="610" height="255" class="size-full wp-image-912" srcset="/wp-content/uploads/2010/12/Tassadar_SC2_Cncpt1.jpg 610w, /wp-content/uploads/2010/12/Tassadar_SC2_Cncpt1-300x125.jpg 300w" sizes="(max-width: 610px) 100vw, 610px" /></a><p id="caption-attachment-912" class="wp-caption-text">The original artwork.</p></div>
<div id="attachment_914" style="width: 610px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/12/pumpkin3.jpg"><img aria-describedby="caption-attachment-914" loading="lazy" src="/wp-content/uploads/2010/12/pumpkin3.jpg" alt="Burnt pumpkin" title="pumpkin3" width="600" height="450" class="size-full wp-image-914" srcset="/wp-content/uploads/2010/12/pumpkin3.jpg 600w, /wp-content/uploads/2010/12/pumpkin3-300x225.jpg 300w" sizes="(max-width: 600px) 100vw, 600px" /></a><p id="caption-attachment-914" class="wp-caption-text">It looks good, but it is very... very badly burnt</p></div>
<div id="attachment_915" style="width: 610px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/12/pumpkin.jpg"><img aria-describedby="caption-attachment-915" loading="lazy" src="/wp-content/uploads/2010/12/pumpkin.jpg" alt="Lit pumpkin" title="pumpkin" width="600" height="450" class="size-full wp-image-915" srcset="/wp-content/uploads/2010/12/pumpkin.jpg 600w, /wp-content/uploads/2010/12/pumpkin-300x225.jpg 300w" sizes="(max-width: 600px) 100vw, 600px" /></a><p id="caption-attachment-915" class="wp-caption-text">It&#039;s all lit up, oh boy!</p></div>
<h2>Design #2: Tychus</h2>
<p>I was impressed with the amount of precision you could get with this technique, but the small size of the pumpkin meant that I was limited in the amount of detail I could accurately display.  I wanted to try again with something a little less involved – the face of Tychus Findlay, one of the main characters in StarCraft 2 and also the image that announced the release of the game several years ago (Blizzard had promised never to make a sequel, so this announcement image is iconic).</p>
<p>This one was amazing, but only when you looked at it correctly.  Check out the black and white one at the bottom.</p>
<p><a href="/wp-content/uploads/2010/12/pumpkin2_original.jpg"><img loading="lazy" src="/wp-content/uploads/2010/12/pumpkin2_original.jpg" alt="Tychus" title="pumpkin2_original" width="500" height="367" class="aligncenter size-full wp-image-917" srcset="/wp-content/uploads/2010/12/pumpkin2_original.jpg 500w, /wp-content/uploads/2010/12/pumpkin2_original-300x220.jpg 300w" sizes="(max-width: 500px) 100vw, 500px" /></a></p>
<div id="attachment_918" style="width: 610px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/12/tychus.jpg"><img aria-describedby="caption-attachment-918" loading="lazy" src="/wp-content/uploads/2010/12/tychus.jpg" alt="" title="tychus" width="600" height="720" class="size-full wp-image-918" srcset="/wp-content/uploads/2010/12/tychus.jpg 600w, /wp-content/uploads/2010/12/tychus-250x300.jpg 250w" sizes="(max-width: 600px) 100vw, 600px" /></a><p id="caption-attachment-918" class="wp-caption-text">Halloween It&#039;s About Time... </p></div>
<p>In conclusion, my camera isn’t very good, the pumpkins were too small, and I didn’t have enough time to create original artwork that worked well for this project.  As a result, I didn’t even get an honorable mention!  I don’t mind, though, because now I know how to make awesome pumpkin carvings for next year!</p>
]]></content:encoded>
					
					<wfw:commentRss>/2010/12/a-pumpkin-festival/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>The Weeks that Led to Sponsor Week</title>
		<link>/2010/10/the-weeks-that-led-to-sponsor-week/</link>
					<comments>/2010/10/the-weeks-that-led-to-sponsor-week/#respond</comments>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Sun, 24 Oct 2010 20:46:45 +0000</pubDate>
				<category><![CDATA[Glass Infrastructure]]></category>
		<category><![CDATA[MIT]]></category>
		<category><![CDATA[Wallpaper]]></category>
		<category><![CDATA[arduino]]></category>
		<category><![CDATA[MIT Media Lab]]></category>
		<category><![CDATA[sensors]]></category>
		<category><![CDATA[Sponsors]]></category>
		<guid isPermaLink="false">/?p=198</guid>

					<description><![CDATA[The Media Lab has a giant tower full of gold coins, which students and faculty use to relax as they swim around it and make tunnels.  The tower doesn&#8217;t fill itself, though &#8212; sponsors do!  The Lab is funded by companies across the world, and in return those companies get rights to any intellectual property [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>The Media Lab has a giant tower full of gold coins, which students and faculty use to relax as they <a href="http://www.youtube.com/watch?v=aPX5mRSQ3pw" target="_blank">swim around it and make tunnels</a>.  The tower doesn&#8217;t fill itself, though &#8212; sponsors do!  The Lab is funded by companies across the world, and in return those companies get rights to any intellectual property created there.  I haven&#8217;t been around long enough to know if this ends up twisting people&#8217;s research in special directions, but I get the idea that it does not; people here seem to work on whatever inspires them in the moment.</p>
<p>The reason I&#8217;m explaining all this is to give background for why I&#8217;ve been extra busy for the past three weeks &#8212; preparing for and participating in sponsor week.  This is a bi-annual celebration where all the sponsors come in to see what sorts of insanity have been going on.  As a first year grad student I was encouraged but not necessarily expected to have any demos of my own to show off, but I ended up getting involved with two projects that ultimately yielded something worth showing.</p>
<h2>Exhibit A: Glass Infrastructure</h2>
<p>The new building has a network of giant touch screens which are located outside of each lab-space.  Each screen is set up to display information about whatever research groups are located nearby, which allows visitors to explore the projects being worked on inside.  The screens are ALSO wired up with RFID readers &#8212; which means if a person has an RFID card the reader can tell who they are, and the interface can change itself based on their interests.</p>
<div id="attachment_907" style="width: 410px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/10/GI_21.jpg"><img aria-describedby="caption-attachment-907" loading="lazy" src="/wp-content/uploads/2010/10/GI_21.jpg" alt="" title="GI_21" width="400" height="533" class="size-full wp-image-907" srcset="/wp-content/uploads/2010/10/GI_21.jpg 400w, /wp-content/uploads/2010/10/GI_21-225x300.jpg 225w" sizes="(max-width: 400px) 100vw, 400px" /></a><p id="caption-attachment-907" class="wp-caption-text">The screen outside of my lab space</p></div>
<p>It turns out that these screens are actually a research project!  They were set up earlier in the year for the previous sponsor week as a joint effort between four groups at the lab.  My adviser suggested I get involved in the creation of &#8220;version 2&#8221; which turned out to be a complete redesign of the interface.  The team consisted of about 7 people, and I helped design and implement the new front end (i.e. the part that actually gets used).</p>
<p>The OLD interface was pretty much two interfaces in one.  The first interface was a mini directory, which listed the research groups in that space and had a quick description of the group along with a rotating display of the projects being worked on by whichever group was being highlighted at that moment.  From there the user could navigate to the second interface by selecting one of those projects.</p>
<p>The second interface simply showed 5 projects at once &#8212; the primary project was whatever the user picked, and the other 4 projects were &#8220;similar projects&#8221; which the system would select.  Users with RFID tags could also &#8220;charm&#8221; projects (i.e. favorite them), which meant that whenever they walked to a screen they could share favorites with other people or quickly jump to learn more.</p>
<p>There were several problems with the old interface.  The first was that people were not really part of it &#8212; you didn&#8217;t know who was in the group or who was working on a given project.  The second was that you didn&#8217;t know WHY other projects were being suggested, you pretty much had to guess.  For the new design we wanted to try to create an experience that provided this extra information, but also somehow combined the two &#8220;views&#8221; into one consistent view.</p>
<p>The redesign process was exhausting!  There were many intense discussions between the more front-end focused people on how to achieve everything we wanted in the UI, and after about two weeks of mockups and prototypes we finally had something that we actually felt had some real potential.  The projects are now clustered together based on the &#8220;ideas&#8221; that they share, and we have a completely new way of navigating the people, projects, and research groups at the lab.</p>
<div id="attachment_908" style="width: 410px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/10/GI_1.jpg"><img aria-describedby="caption-attachment-908" loading="lazy" src="/wp-content/uploads/2010/10/GI_1.jpg" alt="" title="GI_1" width="400" height="300" class="size-full wp-image-908" srcset="/wp-content/uploads/2010/10/GI_1.jpg 400w, /wp-content/uploads/2010/10/GI_1-300x225.jpg 300w" sizes="(max-width: 400px) 100vw, 400px" /></a><p id="caption-attachment-908" class="wp-caption-text">My group&#039;s screen</p></div>
<h2>Exhibit B: Wall Paper</h2>
<p>The second project I worked on was a solo project (although I got a lot of help and advice from my fellow grad students!)  My group once had an installment called the &#8220;octo display&#8221; which was 8 identical HD screens all connected to one computer.  This display was dismantled when my group moved into the new building, and since then the screens have been sitting around gathering dust.</p>
<p>Rather than let them go to waste, though, we decided that it would be interesting to put them up in a long line and use proximity sensors to detect where people were standing in front of them.  The idea was that eventually there will be a lot of surfaces with the ability to display information, but that will get noisy fast if all of the displays are constantly rendering things.  I volunteered to give it a shot, and I&#8217;m glad I did!</p>
<p>Building the thing was pretty rewarding.  For one thing I learned how to use sensors, and for another I learned how difficult it is to mount 8 screens in a straight and level line.  You can read more about the construction of the wall <a href="http://fab.cba.mit.edu/classes/MIT/863.10/people/dan.schultz/a4.html">here</a> &#8212; I ended up using a giant robot to carve out the mount boards and drill holes in exactly the right locations.</p>
<p>The sensor part of it is also pretty cool: there are these devices which you feed power into and it uses IR to detect the distance of objects in front of them.  Depending on the distance, the devices output a sliding voltage (when you walk closer, the voltage goes up).  This means that you can write some code to analyze the voltage and, if you put one of them in front of each monitor, write a program that knows where people are standing.</p>
<div id="attachment_910" style="width: 410px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/10/wall_1.jpg"><img aria-describedby="caption-attachment-910" loading="lazy" src="/wp-content/uploads/2010/10/wall_1.jpg" alt="" title="wall_1" width="400" height="300" class="size-full wp-image-910" srcset="/wp-content/uploads/2010/10/wall_1.jpg 400w, /wp-content/uploads/2010/10/wall_1-300x225.jpg 300w" sizes="(max-width: 400px) 100vw, 400px" /></a><p id="caption-attachment-910" class="wp-caption-text">A quick demo program I wrote -- the number reflects the voltage and the screen turns green when someone is standing in front of it.</p></div>
<p>For anyone interested in more of the details, I used an <a href="http://arduino.cc/">Arduino</a> for the first time to collect the raw voltage information (I&#8217;ll explain more about what that means in a future post), and then I wrote a quick python script to pull that information off of the Arduino and drop it into a file accessible to the web, and then I had a web page which read that data and responded appropriately when someone walked up to a screen.</p>
<div id="attachment_909" style="width: 410px" class="wp-caption aligncenter"><a href="/wp-content/uploads/2010/10/wall_2.jpg"><img aria-describedby="caption-attachment-909" loading="lazy" src="/wp-content/uploads/2010/10/wall_2.jpg" alt="" title="wall_2" width="400" height="300" class="size-full wp-image-909" srcset="/wp-content/uploads/2010/10/wall_2.jpg 400w, /wp-content/uploads/2010/10/wall_2-300x225.jpg 300w" sizes="(max-width: 400px) 100vw, 400px" /></a><p id="caption-attachment-909" class="wp-caption-text">Erek using an almost finished version the night before.</p></div>
<p>For the final demo I tied the screens into the New York Times API.  Each screen displayed a word or phrase (i.e. &#8220;Healthcare&#8221; or &#8220;MIT Media Lab&#8221;) and when you walked up to a screen it would pull up an article from the NYT relevant to that topic.  It turned out pretty nicely, although there was a very slight amount of lag.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2010/10/the-weeks-that-led-to-sponsor-week/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>

<!--
Performance optimized by W3 Total Cache. Learn more: https://www.boldgrid.com/w3-total-cache/

Page Caching using disk: enhanced (SSL caching disabled) 
Minified using disk
Database Caching using disk

Served from: slifty.com @ 2021-05-25 23:12:44 by W3 Total Cache
-->