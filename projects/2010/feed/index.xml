<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>2010 &#8211; Sorry for the Spam</title>
	<atom:link href="/projects/2010/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>The Adventures of Dan Schultz</description>
	<lastBuildDate>Thu, 04 Feb 2016 00:38:12 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.7.2</generator>
	<item>
		<title>The Glass Infrastructure</title>
		<link>/project/the-glass-infrastructure/</link>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Thu, 04 Feb 2016 00:38:12 +0000</pubDate>
				<guid isPermaLink="false">http://192.241.162.137/?post_type=project&#038;p=2340</guid>

					<description><![CDATA[The Glass Infrastructure makes it easy for people to understand what is going on in a building. It is a network of large touch screen displays set up throughout the MIT Media Lab which allow anyone to explore the network of groups, people, and projects at the lab. Thanks to RFID it also knows who [&#8230;]]]></description>
										<content:encoded><![CDATA[<h2>Video</h2>
<p><iframe loading="lazy" src="http://player.vimeo.com/video/50434433" width="500" height="281" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></p>
<h2>Long Description</h2>
<p>The Media Lab gets a lot of visitors.  People bring in friends and family, sponsors send representatives, and others just wander in off of the street.  The Glass Ingrastructure is designed to help anyone quickly and effectively explore the kind of work being done in the building without having to bother us.  Basically, grad students really just don&#8217;t like talking to people if they can avoid it.</p>
<p>The system is made up of about 30 giant touch screens, wired to mac minis and RFID readers.  They are located throughout the Media Lab&#8217;s old and new buildings, and display maps, projects, and other applications.</p>
<p>When I arrived the Glass Infrastructure had a fairly linear interface.  Each screen displayed a rotating list of nearby projects based on where it was placed.  Our goal was to redesign the entire thing, building on the systems already set up.  We had a pretty large team too (about nine people) working on various parts of the product.</p>
<p>We wanted to reflect the relationship between people and projects without overwhelming the user.  There also needed to be a way for people carrying RFID tags to &#8220;favorite&#8221; different projects, and view a list of their favorites on the bottom of the screen.  After weeks of discussion and thrown out designs we came up with the molecule interface.</p>
<p>I spent most of my time working on client side middleware, middle learning a bit more about jQuery at the same time.  The backend was a RESTful API that worked with the database in addition to some fancy Natural Language Processing (NLP) tech which automatically found project relationships based on their descriptions.</p>
<p>The design that we came up with is still in use today, and the Glass Infrastructure has become a core part of the visitor experience at the Media Lab.  We have also set up a few screens in other parts of the world (Spain, for instance) so that sponsor companies can have a window into the work being done here.</p>
<h2>Technologies</h2>
<ul>
<li>jQuery</li>
<li>CSS3</li>
</ul>
<h2>Papers, Posts and Press</h2>
<ul>
<li><a href='/wp-content/uploads/2012/09/GIPaper.pdf'>The Glass Infrastructure: Using Common Sense to Create a Dynamic, Place-Based Social Information System</a> (Havasi, 2011)</li>
</ul>
<h2>Testimonials</h2>
<blockquote><p>You know what would be better than asking me?  Going over and prodding that screen over there.<br />
&#8211; Media Lab Grad Students
</p></blockquote>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>If These Walls Could Tweet</title>
		<link>/project/if-these-walls-could-tweet/</link>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Thu, 04 Feb 2016 00:32:31 +0000</pubDate>
				<guid isPermaLink="false">http://192.241.162.137/?post_type=project&#038;p=2337</guid>

					<description><![CDATA[What if your living room had a Twitter feed? If These Walls Could Tweet is a set of sensors that can send messages on Twitter when triggered. Now when the lights go out your room can tell the world how it feels about it.]]></description>
										<content:encoded><![CDATA[<h2>Long Description</h2>
<p>This was my final project in <a href="http://fab.cba.mit.edu/classes/MIT/863.10/people/dan.schultz/">How to Make Almost Anything</a>.  The idea was originally an artistic/troll project: I wanted to create a modern day printing press.  You would line up the letters, spread the ink, and press it onto paper.  The message would go on the paper as you would expect, but the type blocks would secretly be digital, and the message would also go directly onto Twitter.</p>
<p>I decided to change course because, while that application was a nice statement about legacy media, it seemed that abstracting the interaction might be more useful.  It turned out that group members had talked about the idea of connecting more things to the internet and <a href="http://blog.johnkestner.com/post/388081897/social-networking-for-lonely-objects">using Twitter as a way for those things to communicate</a> long before I had arrived.</p>
<p>I wanted to be able to swap out sensors, so I designed three types of circuit:</p>
<ul>
<li><strong>A hub</strong> which did the communication with the Python that sent out tweets.</li>
<li><strong>Chain-able receivers</strong> which could be connected together, allowing for any number of sensors to be added.</li>
<li><strong>Sensor modules</strong> which could be plugged into receivers.  These would be responsible for measuring whatever the sensor measured and triggering the hub to send tweets.</li>
</ul>
<p>I made four sensor modules. I started with a simple four-state button that you could set to hold a static value (e.g. &#8220;happy, sad, bored, excited&#8221;).  Then I moved onto using a light sensor, a temperature sensor, and then I wrapped up with a proximity sensor.  This kit was enough to warrant a mascot (the pet rock I had created as an earlier project) and tape the proximity sensor on his head.  He talked about all sorts of things, like when people walked by, or when he felt lonely, or when it got too dark.</p>
<p>Behind the googley eyes, sensors would trigger events when their readings changed significantly.  After an event trigger, the hub would then ask all of the modules to share their messages to the world, and those messages would be passed to a Python script over USB.  The Python would then send it to Twitter.</p>
<p>Honestly, I spent most of my time learning to make the circuits (and make them modular), so I wasn&#8217;t able to implement the full vision.  That vision would have included wireless functionality, direct communication with Twitter (bypassing python), a more robust set of logical operators (e.g. &#8220;count the number of people that entered a room&#8221;), additional sensors, and far more pithy quotes.</p>
<p>Basically what I wanted it to look like was <a href="http://supermechanical.com/twine/">Twine</a>, which came a year later from the two Info Eco alums who had originally explored this space.</p>
<h2>Posts and Press</h2>
<ul>
<li><a href="http://fab.cba.mit.edu/classes/MIT/863.10/people/dan.schultz/final.html">My How to Make Almost Anything blog post</a></li>
</ul>
<h2>Technologies</h2>
<ul>
<li>C</li>
<li>Milling Machines (to create the traces)</li>
<li>Sensors, solder, and microcontrollers</li>
<li>Python</li>
</ul>
<h2>Testimonials</h2>
<blockquote><p>What is this, some kind of party?  Don&#8217;t you know the neighbors are trying to sleep?<br />
&#8211; Your living room
</p></blockquote>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Jack-o-Laser</title>
		<link>/project/2333/</link>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Thu, 04 Feb 2016 00:27:17 +0000</pubDate>
				<guid isPermaLink="false">http://192.241.162.137/?post_type=project&#038;p=2333</guid>

					<description><![CDATA[If you had access to a laser cutter in October, what is the first thing you would try to do? Obviously you would use it to carve a pumpkin. Nothing more really needs to be said.]]></description>
										<content:encoded><![CDATA[<h2>Videos</h2>
<p><object id="flashObj" width="486" height="412" classid="clsid:D27CDB6E-AE6D-11cf-96B8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=9,0,47,0"><param name="movie" value="http://c.brightcove.com/services/viewer/federated_f9?isVid=1" /><param name="bgcolor" value="#FFFFFF" /><param name="flashVars" value="videoId=1251336574001&#038;playerID=2227271001&#038;playerKey=AQ~~,AAAAADqBmN8~,Yo4S_rZKGX0rYg6XsV7i3F9IB8jNBoiY&#038;domain=embed&#038;dynamicStreaming=true" /><param name="base" value="http://admin.brightcove.com/" /><param name="seamlesstabbing" value="false" /><param name="allowFullScreen" value="true" /><param name="swLiveConnect" value="true" /><param name="allowScriptAccess" value="always" /><embed src="http://c.brightcove.com/services/viewer/federated_f9?isVid=1" bgcolor="#FFFFFF" flashVars="videoId=1251336574001&#038;playerID=2227271001&#038;playerKey=AQ~~,AAAAADqBmN8~,Yo4S_rZKGX0rYg6XsV7i3F9IB8jNBoiY&#038;domain=embed&#038;dynamicStreaming=true" base="http://admin.brightcove.com/" name="flashObj" width="486" height="412" seamlesstabbing="false" type="application/x-shockwave-flash" allowFullScreen="true" swLiveConnect="true" allowScriptAccess="always" pluginspage="http://www.macromedia.com/shockwave/download/index.cgi?P1_Prod_Version=ShockwaveFlash"></embed></object></p>
<h2>Long Description</h2>
<p>This started as simply a fun way to play with a laser cutter.  Actually, it ended that way too.  In fact, it never really drifted from that status.  However, carving pumpkins with a laser had some interesting challenges.</p>
<p>Laser cutters usually burn away material like acrylic or cardboard to slice pieces out of a flat material.  This is great because the laser has a focal point where the clean cut will happen.  If you are out of focus then the burned hole will either be too big or it won&#8217;t cut the material at all.  If you&#8217;re working with a flat plane you can focus it in one spot and be fine.</p>
<p>If you are carving into a cylinder (for instance a can of baked beans), then you don&#8217;t have a common height to focus onto!  Fortunately for me, the laser cutter at the Media Lab has a lathe attachment.  With a lathe you simulate a flat plane by converting the y axis into rotation (meaning you could &#8220;spin&#8221; an object instead of having the laser actually move forward and backward).</p>
<p>Pumpkins aren&#8217;t cans of baked beans, pumpkins are spherical.  The lathe only lets me rotate on one axis, which means that the X axis varies in height too.  I found a really good solution to the problem, which was to ignore it and carve anyway.  It worked, although I lost detail the further I went from the middle.  Meh.</p>
<p>Before you can even pick out a pumpkin you need to take an image and break it into four layers (I used Adobe Illustrator to do this).  Each layer will represent a different brightness, since it will be a different cut depth.  You don&#8217;t need to use four layers &mdash; you could be boring and just use one, for example.  I used four because deep down it just felt right.</p>
<p>It&#8217;s hard to predict the depth of a cut once you do your second pass, because the area around the laser point will often vary in height depending on how many cuts have happened.  For instance if you were to carve the shape of a doughnut, the middle part of the doughnut might begin to sag, which means that additional cuts could accidentally hit the outskirts of the center.  Tiny details have to be deeper (e.g. brighter) or they will be blasted away on later cuts.</p>
<p>More could be done &mdash; e.g. automatic generation of layers based on pumpkin color calibration (carve the pumpkin with varying depths, take a photo of the lit pumpkin, and match it to the photo you want to carve).  We&#8217;ll see what happens!</p>
<h2>Posts and Press</h2>
<ul>
<li><a href="/2010/12/a-pumpkin-festival/">My overview</a></li>
<li><a href="http://www.newscientist.com/video/1251336574001-hightech-pumpkin-carving.html">New Scientist</a></li>
</ul>
<h2>Technologies</h2>
<ul>
<li>Lasers</li>
<li>Adobe Illustrator</li>
</ul>
<h2>Testimonials</h2>
<blockquote><p>Halloween, it&#8217;s about time<br />
&#8211; Tychus Findlay</p></blockquote>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Wall Paper</title>
		<link>/project/wall-paper/</link>
		
		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Thu, 04 Feb 2016 00:05:14 +0000</pubDate>
				<guid isPermaLink="false">http://192.241.162.137/?post_type=project&#038;p=2325</guid>

					<description><![CDATA[Wall Paper is a horizontal line of monitors (12 feet / 16,000 pixels wide) able to stare longingly at you, track your position, and update the information it presents based on where you are standing. This pretty much makes it the Sting of screens because every move you make, every step you take, it is [&#8230;]]]></description>
										<content:encoded><![CDATA[<h2>Long Description</h2>
<p>Wall Paper allows users to explore information by navigating through physical space.</p>
<p>This demo has undergone several iterations but the overall architecture has remained consistent: there is a browser-based client (JavaScript / HTML / CSS) separated across eight windows, a server (NodeJS) which listens for position updates and manages state, and a sensor component (Python / C) which does the actual position tracking.</p>
<p>The first iteration used infrared (IR) sensors and Arduino to track about 10 points evenly distributed across the eight displays. This provided approximately one data point per screen. A &#8220;newspaper&#8221; was spread across the screens so that each one displayed a section title. To read a given section you would walk up to the appropriate screen. The sensors would detect you, pass that detection onto the client, and an article from the screen&#8217;s section would fade in an article for you to read.</p>
<p>The second iteration replaced the IR sensors with a Microsoft Kinect, resulting in a much higher resolution depth map. Instead of the 10 depth points I now had access to closer to 1000, and I could track positions far more consistently. The interface was also replaced to display a bar-chart representing 20 years of reporting by the New York Times. Each month had a bar broken into four colors representing coverage of &#8220;Afghanistan,&#8221; &#8220;Iraq,&#8221; &#8220;Wall Street,&#8221; and &#8220;Protests.&#8221; You could walk up to a part of the screen to learn about a specific month, and as you got even closer you could see headlines for each of the four content types scrolling across your section of the display.</p>
<p>Of course, it was also used to mess with people. There was a time when the content would get smaller as people walked closer.</p>
<h2>Technologies</h2>
<ul>
<li>Arduino</li>
<li>C</li>
<li>HTML / CSS</li>
<li>jQuery</li>
<li>NodeJS</li>
<li>Python</li>
</ul>
<h2>Testimonials</h2>
<blockquote><p>So what you&#8217;re saying is that this project has failed both in terms of user experience, and in terms of graphic design?<br />
&#8211; Henry Holtzman
</p></blockquote>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>

<!--
Performance optimized by W3 Total Cache. Learn more: https://www.boldgrid.com/w3-total-cache/

Page Caching using disk: enhanced (SSL caching disabled) 
Minified using disk
Database Caching using disk

Served from: slifty.com @ 2021-05-25 23:13:12 by W3 Total Cache
-->